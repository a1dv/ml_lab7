{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Zgoi8i6plWlO"
      },
      "source": [
        "### О ЛР:\n",
        "\n",
        "- Coding Gradient boosting\n",
        "\n",
        "----\n",
        "\n",
        "#### Самостоятельная оценка результатов\n",
        "\n",
        "Для удобства проверки, исходя из набора решенных задач, посчитайте свою максимальную оценку (Она тут равняется 6).\n",
        "\n",
        "**Оценка**:\n",
        "\n",
        "***DeadLine - 28.05.2024 23:59***\n",
        "\n",
        "### Формат сдачи\n",
        "Задания сдаются через lms. Вы прикрепляете **ССЫЛКУ НА ПУБЛИЧНЫЙ РЕПОЗИТОРИЙ**, где выполнено ваше задание. Иначе задание не проверяется."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1XDUNTn4lWlP"
      },
      "outputs": [],
      "source": [
        "from warnings import filterwarnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy.sparse import load_npz\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yvolL0KvlWlQ"
      },
      "outputs": [],
      "source": [
        "x = load_npz(\"x.npz\")\n",
        "y = np.load(\"y.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo8R55-mjrCN",
        "outputId": "2a45c3ef-dd5a-4daf-ffc8-56402d114690"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1, -1, ..., -1, -1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "PRMjj9ZslWlQ"
      },
      "source": [
        "Разделим на обучающую, валидационную и тестовую выборки (`random_state` оставьте равным 666 для воспроизводимости)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hme6Cf0HlWlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e4d649-260d-4141-bb79-dd7bd4a2476c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18825, 169), (2354, 169), (2353, 169))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=666\n",
        ")\n",
        "\n",
        "x_test, x_valid, y_test, y_valid = train_test_split(\n",
        "    x_test, y_test, test_size=0.5, random_state=666\n",
        ")\n",
        "\n",
        "x_train.shape, x_valid.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tHaBuXarlWlR"
      },
      "source": [
        "## Задание 1. Реализация градиентного бустинга [2 балла]\n",
        "\n",
        "Необходимо дописать код в файле `boosting.py`. Уже создан шаблон класса `Boosting`, который можно модифицировать по своему усмотрению.\n",
        "\n",
        "### Описание функций:\n",
        "\n",
        "#### `__init__`\n",
        "\n",
        "Конструктор класса принимает следующие параметры:\n",
        "\n",
        "- `base_model_class` — класс базовой модели для бустинга.\n",
        "- `base_model_params` — словарь гиперпараметров для базовой модели.\n",
        "- `n_estimators` — количество базовых моделей для обучения.\n",
        "- `learning_rate` — темп обучения, должен быть в диапазоне (0, 1].\n",
        "- `subsample` — доля обучающей выборки для тренировки базовой модели (размер бутстрап-выборки относительно исходной).\n",
        "- `early_stopping_rounds` — число итераций без улучшения на валидационной выборке, после которых обучение прекращается.\n",
        "- `plot` — флаг для построения графика качества моделей после обучения.\n",
        "\n",
        "#### `fit`\n",
        "\n",
        "Метод `fit` принимает обучающую и валидационную выборки.\n",
        "\n",
        "1. Инициализируем нулевую модель и делаем предсказания (например, все нули) для обеих выборок.\n",
        "2. Обучаем `n_estimators` базовых моделей:\n",
        "   - Обучаем новую базовую модель на текущих остатках.\n",
        "   - Обновляем предсказания на обучающей и валидационной выборках.\n",
        "   - Рассчитываем ошибки на обеих выборках с помощью `loss_fn`.\n",
        "   - Проверяем условия для ранней остановки.\n",
        "\n",
        "3. Если флаг `plot` установлен, строим график качества после обучения всех моделей.\n",
        "\n",
        "#### `fit_new_base_model`\n",
        "\n",
        "Метод `fit_new_base_model` принимает обучающую выборку и текущие предсказания для неё.\n",
        "\n",
        "1. Генерируем бутстрап-выборку.\n",
        "2. Обучаем базовую модель на этой выборке.\n",
        "3. Оптимизируем значение гаммы.\n",
        "4. Добавляем новую базовую модель и гамму в соответствующие списки (учитывая `learning_rate`).\n",
        "\n",
        "#### `predict_proba`\n",
        "\n",
        "Метод `predict_proba` принимает выборку для предсказания вероятностей.\n",
        "\n",
        "1. Суммируем предсказания базовых моделей (учитывая гамму и `learning_rate`).\n",
        "2. Применяем сигмоидальную функцию для получения вероятностей."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "def score(clf, x, y):\n",
        "    return roc_auc_score(y == 1, clf.predict_proba(x)[:, 1])\n",
        "\n",
        "\n",
        "class Boosting:\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            base_model_params: dict = None,\n",
        "            n_estimators: int = 10,\n",
        "            learning_rate: float = 0.1,\n",
        "            subsample: float = 0.3,\n",
        "            early_stopping_rounds: int = None,\n",
        "            plot: bool = False,\n",
        "    ):\n",
        "        self.base_model_class = DecisionTreeRegressor\n",
        "        self.base_model_params: dict = {} if base_model_params is None else base_model_params\n",
        "\n",
        "        self.n_estimators: int = n_estimators\n",
        "\n",
        "        self.models: list = []\n",
        "        self.gammas: list = []\n",
        "\n",
        "        self.learning_rate: float = learning_rate\n",
        "        self.subsample: float = subsample\n",
        "\n",
        "        self.early_stopping_rounds: int = early_stopping_rounds\n",
        "        if early_stopping_rounds is not None:\n",
        "            self.validation_loss = np.full(self.early_stopping_rounds, np.inf)\n",
        "\n",
        "        self.plot: bool = plot\n",
        "\n",
        "        self.history = defaultdict(list)\n",
        "\n",
        "        self.sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "        self.loss_fn = lambda y, z: -np.log(self.sigmoid(y * z)).mean()\n",
        "        self.loss_derivative = lambda y, z: -y * self.sigmoid(-y * z)\n",
        "\n",
        "    def fit_new_base_model(self, x, y, predictions):\n",
        "        \"\"\"\n",
        "        Обучает новую базовую модель и добавляет ее в ансамбль.\n",
        "\n",
        "        Параметры\n",
        "        ----------\n",
        "        x : array-like, форма (n_samples, n_features)\n",
        "            Массив признаков для набора данных.\n",
        "        y : array-like, форма (n_samples,)\n",
        "            Массив целевых значений.\n",
        "        predictions : array-like, форма (n_samples,)\n",
        "            Предсказания текущего ансамбля.\n",
        "\n",
        "        Примечания\n",
        "        ----------\n",
        "        Эта функция добавляет новую модель и обновляет ансамбль.\n",
        "        \"\"\"\n",
        "\n",
        "        bootstrap_indices = np.random.choice(\n",
        "            np.arange(x.shape[0]),\n",
        "            size=int(self.subsample * x.shape[0]),\n",
        "            replace=True\n",
        "        )\n",
        "\n",
        "        tree = self.base_model_class(**self.base_model_params)\n",
        "        tree.fit(x[bootstrap_indices], self.loss_derivative(y[bootstrap_indices], predictions[bootstrap_indices]))\n",
        "\n",
        "        new_predictions = tree.predict(x)\n",
        "\n",
        "        gamma = self.find_optimal_gamma(y, predictions, new_predictions)\n",
        "\n",
        "        self.gammas.append(gamma)\n",
        "        self.models.append(tree)\n",
        "\n",
        "\n",
        "    def fit(self, x_train, y_train, x_valid, y_valid):\n",
        "        \"\"\"\n",
        "        Обучает модель на тренировочном наборе данных и выполняет валидацию на валидационном наборе.\n",
        "\n",
        "        Параметры\n",
        "        ----------\n",
        "        x_train : array-like, форма (n_samples, n_features)\n",
        "            Массив признаков для тренировочного набора.\n",
        "        y_train : array-like, форма (n_samples,)\n",
        "            Массив целевых значений для тренировочного набора.\n",
        "        x_valid : array-like, форма (n_samples, n_features)\n",
        "            Массив признаков для валидационного набора.\n",
        "        y_valid : array-like, форма (n_samples,)\n",
        "            Массив целевых значений для валидационного набора.\n",
        "        \"\"\"\n",
        "        train_predictions = np.zeros(y_train.shape[0])\n",
        "        valid_predictions = np.zeros(y_valid.shape[0])\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            self.fit_new_base_model(x_train, y_train, train_predictions)\n",
        "\n",
        "            train_predictions += self.learning_rate * self.gammas[i] * self.models[i].predict(x_train)\n",
        "            valid_predictions += self.learning_rate * self.gammas[i] * self.models[i].predict(x_valid)\n",
        "\n",
        "            train_loss = self.loss_fn(y_train, train_predictions)\n",
        "            valid_loss = self.loss_fn(y_valid, valid_predictions)\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            if self.early_stopping_rounds is not None:\n",
        "                if valid_loss < np.min(self.validation_loss):\n",
        "                    self.validation_loss = np.roll(self.validation_loss, -1)\n",
        "                    self.validation_loss[-1] = valid_loss\n",
        "                else:\n",
        "                    if np.all(valid_loss >= self.validation_loss):\n",
        "                        self.n_estimators = i + 1\n",
        "                        break\n",
        "\n",
        "        if self.plot:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.plot(range(self.n_estimators), self.history['train_loss'], label='Train Loss')\n",
        "            plt.plot(range(self.n_estimators), self.history['valid_loss'], label='Valid Loss')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.title('Training and Validation Loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        \"\"\"\n",
        "        Вычисляет вероятности принадлежности классу для каждого образца.\n",
        "\n",
        "        Параметры\n",
        "        ----------\n",
        "        x : array-like, форма (n_samples, n_features)\n",
        "            Массив признаков для набора данных.\n",
        "\n",
        "        Возвращает\n",
        "        ----------\n",
        "        probabilities : array-like, форма (n_samples, n_classes)\n",
        "            Вероятности для каждого класса.\n",
        "        \"\"\"\n",
        "        predictions = np.zeros(x.shape[0])\n",
        "        for gamma, model in zip(self.gammas, self.models):\n",
        "            predictions += self.learning_rate * gamma * model.predict(x)\n",
        "\n",
        "        probabilities = self.sigmoid(predictions)\n",
        "        return np.stack((1 - probabilities, probabilities), axis=1)\n",
        "\n",
        "    def find_optimal_gamma(self, y, old_predictions, new_predictions) -> float:\n",
        "        \"\"\"\n",
        "        Находит оптимальное значение гаммы для минимизации функции потерь.\n",
        "\n",
        "        Параметры\n",
        "        ----------\n",
        "        y : array-like, форма (n_samples,)\n",
        "            Целевые значения.\n",
        "        old_predictions : array-like, форма (n_samples,)\n",
        "            Предыдущие предсказания ансамбля.\n",
        "        new_predictions : array-like, форма (n_samples,)\n",
        "            Новые предсказания базовой модели.\n",
        "\n",
        "        Возвращает\n",
        "        ----------\n",
        "        gamma : float\n",
        "            Оптимальное значение гаммы.\n",
        "\n",
        "        Примечания\n",
        "        ----------\n",
        "        Значение гаммы определяется путем минимизации функции потерь.\n",
        "        \"\"\"\n",
        "        gammas = np.linspace(start=0, stop=1, num=100)\n",
        "        losses = [self.loss_fn(y, old_predictions + gamma * new_predictions) for gamma in gammas]\n",
        "\n",
        "        return gammas[np.argmin(losses)]\n",
        "\n",
        "    def score(self, x, y):\n",
        "        return score(self, x, y)\n",
        "\n",
        "    @property\n",
        "    def feature_importances_(self):\n",
        "        \"\"\"\n",
        "        Возвращает важность признаков в обученной модели.\n",
        "\n",
        "        Возвращает\n",
        "        ----------\n",
        "        importances : array-like, форма (n_features,)\n",
        "            Важность каждого признака.\n",
        "\n",
        "        Примечания\n",
        "        ----------\n",
        "        Важность признаков определяется по вкладу каждого признака в финальную модель.\n",
        "        \"\"\"\n",
        "        if not self.models:\n",
        "            return np.zeros(self.models[0].feature_importances_.shape)\n",
        "\n",
        "        importances = sum(model.feature_importances_ for model in self.models)\n",
        "        return importances / np.sum(importances)"
      ],
      "metadata": {
        "id": "o1ZMd3zugRP9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(y_train == -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8uPaLDoi1s5",
        "outputId": "b229faf1-8602-4024-ced8-644b9be4324c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6510"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "l7wWK5RplWlT"
      },
      "source": [
        "### Проверка кода\n",
        "\n",
        "У автора задания всё учится около одной секунды."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "00lZjzI3lWlT",
        "outputId": "aeca52e8-210d-4c48-8659-9865540beef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train ROC-AUC 0.5000\n",
            "Valid ROC-AUC 0.5000\n",
            "Test ROC-AUC 0.5000\n"
          ]
        }
      ],
      "source": [
        "boosting = Boosting()\n",
        "#% time\n",
        "boosting.fit(x_train, y_train, x_valid, y_valid)\n",
        "\n",
        "assert len(boosting.models) == boosting.n_estimators\n",
        "assert len(boosting.gammas) == boosting.n_estimators\n",
        "\n",
        "assert boosting.predict_proba(x_test).shape == (x_test.shape[0], 2)\n",
        "\n",
        "print(f'Train ROC-AUC {boosting.score(x_train, y_train):.4f}')\n",
        "print(f'Valid ROC-AUC {boosting.score(x_valid, y_valid):.4f}')\n",
        "print(f'Test ROC-AUC {boosting.score(x_test, y_test):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "MlU-c9CxlWlU"
      },
      "source": [
        "## Задание 2. Обучение градиентного бустинга [0.5 балла]\n",
        "\n",
        "Оцените качество вашей реализации градиентного бустинга на тестовой выборке, используя базовые модели — решающие деревья с различной максимальной глубиной. Метрикой будет ROC-AUC.\n",
        "\n",
        "**Инструкция:**\n",
        "1. Перебирайте значения максимальной глубины деревьев от 1 до 30 с шагом 2.\n",
        "2. Оставьте остальные параметры бустинга по умолчанию.\n",
        "3. Постройте график зависимости качества на обучающей и тестовой выборке от максимальной глубины деревьев."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "depths = range(1, 30, 2)\n",
        "\n",
        "for depth in depths:\n",
        "    boosting = Boosting(base_model_params={'max_depth': depth})\n",
        "    boosting.fit(x_train, y_train, x_valid, y_valid)\n",
        "    results[depth] = {\n",
        "        'train': boosting.score(x_train, y_train),\n",
        "        'test': boosting.score(x_test, y_test)\n",
        "    }\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(list(results.keys()), [results[depth]['train'] for depth in results], label='Train')\n",
        "plt.plot(list(results.keys()), [results[depth]['test'] for depth in results], label='Test')\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('ROC-AUC')\n",
        "plt.title('Boosting Performance vs Max Depth')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "vou3OxJDhGVM",
        "outputId": "0f4b2c75-03ce-4554-89d1-65a5850d43ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bshz0JV6lWlV"
      },
      "source": [
        "**Какая из моделей имеет лучшее качество? Как вы можете это объяснить?**\n",
        "\n",
        "Все модели показывают одинаковый результат"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FwaUsmqlWlV"
      },
      "source": [
        "## Задание 3. Подбор гиперпараметров и поиск оптимальной модели [3 балла]\n",
        "\n",
        "Настройте основные гиперпараметры вашей модели градиентного бустинга, используя валидационную выборку. Подберите параметры как для самого бустинга, так и для базовых моделей.\n",
        "\n",
        "**Рекомендации:**\n",
        "- Используйте библиотеки для автоматизированного подбора гиперпараметров, такие как [Hyperopt](https://github.com/hyperopt/hyperopt) или [Optuna](https://optuna.org/).\n",
        "- Подберите все основные параметры, чтобы найти лучшую модель на валидационной выборке."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna==3.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfoaYLs2Slrt",
        "outputId": "ff4faf45-6cee-4aac-83ce-82326903f85a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna==3.2.0\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna==3.2.0)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting cmaes>=0.9.1 (from optuna==3.2.0)\n",
            "  Downloading cmaes-0.11.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting colorlog (from optuna==3.2.0)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna==3.2.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.2.0) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.2.0) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna==3.2.0) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna==3.2.0) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna==3.2.0)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna==3.2.0) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.2.0) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna==3.2.0) (2.1.5)\n",
            "Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmaes-0.11.1-py3-none-any.whl (35 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 cmaes-0.11.1 colorlog-6.8.2 optuna-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 100)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.5)\n",
        "    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
        "\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "\n",
        "    boosting = Boosting(\n",
        "        base_model_params={\"max_depth\": max_depth},\n",
        "        n_estimators=n_estimators,\n",
        "        learning_rate=learning_rate,\n",
        "        subsample=subsample,\n",
        "    )\n",
        "    boosting.fit(x_train, y_train, x_valid, y_valid)\n",
        "\n",
        "    return boosting.score(x_valid, y_valid)\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "best_params = trial.params\n",
        "best_boosting = Boosting(\n",
        "    base_model_params={\"max_depth\": best_params[\"max_depth\"]},\n",
        "    n_estimators=best_params[\"n_estimators\"],\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    subsample=best_params[\"subsample\"],\n",
        ")\n",
        "best_boosting.fit(x_train, y_train, x_valid, y_valid)\n",
        "\n",
        "print(f\"Train ROC-AUC: {best_boosting.score(x_train, y_train):.4f}\")\n",
        "print(f\"Valid ROC-AUC: {best_boosting.score(x_valid, y_valid):.4f}\")\n",
        "print(f\"Test ROC-AUC: {best_boosting.score(x_test, y_test):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUZeYKJuCaKr",
        "outputId": "866d3f27-f8d6-49f5-881b-d8328ebf26b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-20 20:05:06,458] A new study created in memory with name: no-name-a5d3ee56-021c-4977-a19b-783bc6821ba9\n",
            "[I 2024-09-20 20:05:08,383] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 36, 'learning_rate': 0.21363618797025288, 'subsample': 0.2305741596817738, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:10,665] Trial 1 finished with value: 0.5 and parameters: {'n_estimators': 42, 'learning_rate': 0.46837285394492373, 'subsample': 0.30105873386779697, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:18,561] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 89, 'learning_rate': 0.11971100042026288, 'subsample': 0.44953189421416984, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:23,284] Trial 3 finished with value: 0.5 and parameters: {'n_estimators': 59, 'learning_rate': 0.13257291130121032, 'subsample': 0.7051672863717943, 'max_depth': 5}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:26,140] Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 53, 'learning_rate': 0.08946885921294509, 'subsample': 0.3343360717388468, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:37,842] Trial 5 finished with value: 0.5 and parameters: {'n_estimators': 85, 'learning_rate': 0.4337130228939913, 'subsample': 0.6591416477201131, 'max_depth': 9}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:41,697] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 56, 'learning_rate': 0.40363970158109563, 'subsample': 0.4509672750173378, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:45,549] Trial 7 finished with value: 0.5 and parameters: {'n_estimators': 44, 'learning_rate': 0.2480700596424457, 'subsample': 0.8365161298575386, 'max_depth': 4}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:50,326] Trial 8 finished with value: 0.5 and parameters: {'n_estimators': 54, 'learning_rate': 0.16968593795522352, 'subsample': 0.9324373902526131, 'max_depth': 5}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:56,336] Trial 9 finished with value: 0.5 and parameters: {'n_estimators': 83, 'learning_rate': 0.3261847221434252, 'subsample': 0.5797085637633157, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:57,013] Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 10, 'learning_rate': 0.016743818092472607, 'subsample': 0.12282971968743944, 'max_depth': 8}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:05:58,420] Trial 11 finished with value: 0.5 and parameters: {'n_estimators': 26, 'learning_rate': 0.4794443592457242, 'subsample': 0.18907958497436222, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:00,726] Trial 12 finished with value: 0.5 and parameters: {'n_estimators': 31, 'learning_rate': 0.32758744541731505, 'subsample': 0.27317202187919426, 'max_depth': 7}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:02,524] Trial 13 finished with value: 0.5 and parameters: {'n_estimators': 33, 'learning_rate': 0.4875250645037361, 'subsample': 0.10642585925670206, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:06,376] Trial 14 finished with value: 0.5 and parameters: {'n_estimators': 71, 'learning_rate': 0.2323585346694114, 'subsample': 0.2854956185340229, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:08,334] Trial 15 finished with value: 0.5 and parameters: {'n_estimators': 17, 'learning_rate': 0.3219985569767737, 'subsample': 0.3931885981047955, 'max_depth': 6}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:12,258] Trial 16 finished with value: 0.5 and parameters: {'n_estimators': 42, 'learning_rate': 0.20500402386780073, 'subsample': 0.2471777777807811, 'max_depth': 10}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:16,400] Trial 17 finished with value: 0.5 and parameters: {'n_estimators': 70, 'learning_rate': 0.28855674554143607, 'subsample': 0.3958272096041465, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:22,998] Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 99, 'learning_rate': 0.37825259812560363, 'subsample': 0.2223531804871903, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:25,773] Trial 19 finished with value: 0.5 and parameters: {'n_estimators': 41, 'learning_rate': 0.2709569852300317, 'subsample': 0.5086199631162329, 'max_depth': 4}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:27,197] Trial 20 finished with value: 0.5 and parameters: {'n_estimators': 22, 'learning_rate': 0.3659399574428777, 'subsample': 0.3610530219228618, 'max_depth': 4}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:33,155] Trial 21 finished with value: 0.5 and parameters: {'n_estimators': 99, 'learning_rate': 0.20222431879097658, 'subsample': 0.479115563525521, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:36,225] Trial 22 finished with value: 0.5 and parameters: {'n_estimators': 36, 'learning_rate': 0.14448965021764873, 'subsample': 0.28888397612107963, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:39,757] Trial 23 finished with value: 0.5 and parameters: {'n_estimators': 65, 'learning_rate': 0.09194995679940499, 'subsample': 0.18507072564137578, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:43,251] Trial 24 finished with value: 0.5 and parameters: {'n_estimators': 48, 'learning_rate': 0.43725058682645923, 'subsample': 0.42039856995202257, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:50,240] Trial 25 finished with value: 0.5 and parameters: {'n_estimators': 82, 'learning_rate': 0.2247957938720746, 'subsample': 0.3486762079443773, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:55,391] Trial 26 finished with value: 0.5 and parameters: {'n_estimators': 89, 'learning_rate': 0.26554133727519913, 'subsample': 0.5167699076462756, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:06:59,543] Trial 27 finished with value: 0.5 and parameters: {'n_estimators': 74, 'learning_rate': 0.18418493154187532, 'subsample': 0.33125098149066423, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:04,555] Trial 28 finished with value: 0.5 and parameters: {'n_estimators': 49, 'learning_rate': 0.2316876871466375, 'subsample': 0.43156872400544494, 'max_depth': 6}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:08,996] Trial 29 finished with value: 0.5 and parameters: {'n_estimators': 64, 'learning_rate': 0.1538891231770163, 'subsample': 0.6012570823359097, 'max_depth': 4}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:12,604] Trial 30 finished with value: 0.5 and parameters: {'n_estimators': 61, 'learning_rate': 0.1256560938801331, 'subsample': 0.17268932498948036, 'max_depth': 5}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:15,152] Trial 31 finished with value: 0.5 and parameters: {'n_estimators': 34, 'learning_rate': 0.11014747102671643, 'subsample': 0.7140561708142842, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:22,495] Trial 32 finished with value: 0.5 and parameters: {'n_estimators': 92, 'learning_rate': 0.06060208645786393, 'subsample': 0.5432629736517367, 'max_depth': 5}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:25,888] Trial 33 finished with value: 0.5 and parameters: {'n_estimators': 57, 'learning_rate': 0.14038972632182944, 'subsample': 0.32986277206006864, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:33,294] Trial 34 finished with value: 0.5 and parameters: {'n_estimators': 76, 'learning_rate': 0.1726065928644157, 'subsample': 0.45514895852198195, 'max_depth': 7}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:36,772] Trial 35 finished with value: 0.5 and parameters: {'n_estimators': 49, 'learning_rate': 0.11186005501634631, 'subsample': 0.6924755070569393, 'max_depth': 4}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:39,026] Trial 36 finished with value: 0.5 and parameters: {'n_estimators': 38, 'learning_rate': 0.1700470955805306, 'subsample': 0.619953536931974, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:42,295] Trial 37 finished with value: 0.5 and parameters: {'n_estimators': 29, 'learning_rate': 0.07515159820039463, 'subsample': 0.47538726675480164, 'max_depth': 7}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:43,979] Trial 38 finished with value: 0.5 and parameters: {'n_estimators': 22, 'learning_rate': 0.4401657943790554, 'subsample': 0.7569767637954644, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:07:50,745] Trial 39 finished with value: 0.5 and parameters: {'n_estimators': 46, 'learning_rate': 0.19577343095089705, 'subsample': 0.9905458156828915, 'max_depth': 5}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:01,150] Trial 40 finished with value: 0.5 and parameters: {'n_estimators': 55, 'learning_rate': 0.147793506339537, 'subsample': 0.5778720739099741, 'max_depth': 8}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:04,634] Trial 41 finished with value: 0.5 and parameters: {'n_estimators': 52, 'learning_rate': 0.04952675450275101, 'subsample': 0.3111956717002331, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:07,507] Trial 42 finished with value: 0.5 and parameters: {'n_estimators': 44, 'learning_rate': 0.1214630063332424, 'subsample': 0.23957383003736032, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:12,424] Trial 43 finished with value: 0.5 and parameters: {'n_estimators': 60, 'learning_rate': 0.08820432026409511, 'subsample': 0.3734961092916082, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:14,743] Trial 44 finished with value: 0.5 and parameters: {'n_estimators': 40, 'learning_rate': 0.02855458612247168, 'subsample': 0.27906949951593085, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:19,308] Trial 45 finished with value: 0.5 and parameters: {'n_estimators': 80, 'learning_rate': 0.0979273154184103, 'subsample': 0.40899241148552434, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:20,013] Trial 46 finished with value: 0.5 and parameters: {'n_estimators': 13, 'learning_rate': 0.49658995234531933, 'subsample': 0.1537365157608238, 'max_depth': 1}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:21,850] Trial 47 finished with value: 0.5 and parameters: {'n_estimators': 27, 'learning_rate': 0.46573843729079833, 'subsample': 0.2190520660787687, 'max_depth': 3}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:26,630] Trial 48 finished with value: 0.5 and parameters: {'n_estimators': 66, 'learning_rate': 0.16077328371983618, 'subsample': 0.38007460393236636, 'max_depth': 2}. Best is trial 0 with value: 0.5.\n",
            "[I 2024-09-20 20:08:30,184] Trial 49 finished with value: 0.5 and parameters: {'n_estimators': 53, 'learning_rate': 0.12723994417325366, 'subsample': 0.25897409330616417, 'max_depth': 6}. Best is trial 0 with value: 0.5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value:  0.5\n",
            "  Params: \n",
            "    n_estimators: 36\n",
            "    learning_rate: 0.21363618797025288\n",
            "    subsample: 0.2305741596817738\n",
            "    max_depth: 1\n",
            "Train ROC-AUC: 0.5000\n",
            "Valid ROC-AUC: 0.5000\n",
            "Test ROC-AUC: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hGk-Wt_slWlV"
      },
      "source": [
        "## Задание 4. Интерпретация градиентного бустинга [1 балл]\n",
        "\n",
        "Постройте калибровочную кривую для вашей лучшей модели градиентного бустинга и оцените, насколько точно модель предсказывает вероятности.\n",
        "\n",
        "**Инструкция:**\n",
        "1. Постройте калибровочную кривую для лучшей модели градиентного бустинга.\n",
        "2. Постройте аналогичную кривую для логистической регрессии.\n",
        "3. Сравните полученные результаты и проанализируйте, насколько хорошо каждая модель оценивает вероятности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LdJG4bHClWlV"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8O6bjp2MlWlW"
      },
      "source": [
        "Теперь оценим важность признаков для градиентного бустинга.\n",
        "\n",
        "**Задание:**\n",
        "1. Поскольку базовая модель — дерево из `sklearn`, вычислите важность каждого признака для каждого дерева, используя атрибут `feature_importances_` у `DecisionTreeRegressor`.\n",
        "2. Усредните значения важности по всем деревьям и нормализуйте их так, чтобы сумма была равна единице (убедитесь, что значения неотрицательны).\n",
        "3. Дополните вашу реализацию бустинга, добавив метод `feature_importances_`, который будет возвращать усредненные и нормализованные важности признаков.\n",
        "\n",
        "**Построение графиков:**\n",
        "1. Постройте столбчатую диаграмму важности признаков для градиентного бустинга.\n",
        "2. На соседнем графике изобразите важность признаков для логистической регрессии, используя модули весов.\n",
        "3. Сравните графики и проанализируйте полученные результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y0JNgBk_lWlW"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xheSi2IolWlW"
      },
      "source": [
        "Обычно избыточные признаки могут негативно влиять на качество бустинга. Попробуйте следующее:\n",
        "\n",
        "1. **Отфильтруйте неважные признаки:** Используйте построенную диаграмму важности признаков, чтобы отобрать наиболее незначительные признаки.\n",
        "2. **Обучите модель повторно:** Обучите модель на основе оставшихся признаков с теми же гиперпараметрами.\n",
        "3. **Оцените качество модели:** Сравните результаты новой модели с исходной. Улучшилось ли качество после отфильтровывания незначительных признаков?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Rw9W9MEYlWlW"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pH3489RklWlW"
      },
      "source": [
        "## Задание 5 (бонус). Блендинговое [0.5 балла]\n",
        "\n",
        "Реализуйте блендинг над вашей лучшей моделью и логистической регрессией. Улучшилось ли качество?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FWcDMMVilWlW"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eEF0yJ4vlWlX"
      },
      "source": [
        "## Задание 6 (бонус). Катбустовое [0.5 балла]\n",
        "\n",
        "Запустите [CatBoost](https://catboost.ai/en/docs/concepts/python-quickstart) на наших данных, сравните с вашей реализацией. Где получилось лучше?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebJRoJCaTo5i",
        "outputId": "e5109025-99ae-4112-f288-da124bd2b21c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0lYGhc_clWlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216602d0-1e18-46d5-d325-4bc16b191310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ROC-AUC with CatBoost: 0.8976\n",
            "Test ROC-AUC with my implementation: 0.5000\n",
            "CatBoost achieved better performance.\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=trial.params['n_estimators'],\n",
        "    learning_rate=trial.params['learning_rate'],\n",
        "    depth=trial.params['max_depth'],\n",
        "    subsample=trial.params['subsample'],\n",
        "    verbose=False\n",
        ")\n",
        "catboost_model.fit(x_train, y_train)\n",
        "\n",
        "score_test_catboost = catboost_model.score(x_test, y_test)\n",
        "print(f'Test ROC-AUC with CatBoost: {score_test_catboost:.4f}')\n",
        "\n",
        "print(f'Test ROC-AUC with my implementation: {score_test:.4f}')\n",
        "\n",
        "if score_test_catboost > score_test:\n",
        "    print(\"CatBoost achieved better performance.\")\n",
        "else:\n",
        "    print(\"My implementation achieved better performance.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставьте пожалуйста отзыв о курсе!\n",
        "\n",
        "https://forms.gle/LajA3Xrps6u96Q5A8\n",
        "\n",
        "\n",
        "Это очень важно. Благодаря обратной связи мы будем двигаться в сторону антиградиента)\n"
      ],
      "metadata": {
        "id": "EqHzTXCllZO8"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "210px",
        "width": "492px"
      },
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}